_BASE_: coco/maskformer2_R50_bs16_50ep.yaml
DATASETS:
  TRAIN: ("sior_train_instance",)
  TEST: ("nwpu_val_instance",)
SOLVER:
  IMS_PER_BATCH: 2
  BASE_LR: 0.0000125
  STEPS: [263812, 278468]
  MAX_ITER: 293125
MODEL:
  META_ARCHITECTURE: "SCORE"
  SEM_SEG_HEAD:
    NAME: "SCOREHead"
    NUM_CLASSES: 20
  # backbone part.
  BACKBONE:
    NAME: "CLIP_FCCLIP"
  WEIGHTS: ""
  PIXEL_MEAN: [122.7709383, 116.7460125, 104.09373615]
  PIXEL_STD: [68.5005327, 66.6321579, 70.32316305]
  SCORE:
    RSCLIP_MODEL_NAME: "ViT-L/14"
    RSCLIP_PRETRAINED_WEIGHTS: "RemoteCLIP-ViT-L-14"
    CLIP_MODEL_NAME: "convnext_large_d_320" 
    CLIP_PRETRAINED_WEIGHTS: "laion2b_s29b_b131k_ft_soup"
    EMBED_DIM: 768
    GEOMETRIC_ENSEMBLE_ALPHA: 0.4
    GEOMETRIC_ENSEMBLE_BETA: 0.8
  MASK_FORMER:
    NUM_OBJECT_QUERIES: 300
    TEST:
      SEMANTIC_ON: False
      INSTANCE_ON: True
      PANOPTIC_ON: False
      OBJECT_MASK_THRESHOLD: 0.0

TEST:
  EVAL_PERIOD: 50000
  DETECTIONS_PER_IMAGE: 300
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
OUTPUT_DIR: 'score_sior_instance'
SEED: 42
INPUT:
  IMAGE_SIZE: 512